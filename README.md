# XML producer


## Описание

`kafka-xml-producer` — это сервис на Go, который периодически сканирует указанную NFS директорию, находит XML файлы и отправляет содержимое каждого файла в Kafka-топик.  
После успешной отправки файл переносится в backup директорию, а старые файлы в backup автоматически удаляются по настраиваемому временному порогу.

Основные возможности:
- Отправка XML файлов в Kafka.
- Повторные попытки отправки (retry) с backoff.
- Dead Letter Queue (DLQ) топик для «плохих» сообщений.
- Idempotency на уровне producer’а (ключ сообщения на основе файла).
- Автоархивация и очистка старых файлов в backup.

## Архитектура

Сервис состоит из трёх основных частей:

- **Config слой**  
  Читает YAML-конфигурацию и/или переменные окружения, мапит всё в структуру Go.

- **Kafka producer**  
  Обертка над Kafka-клиентом, которая:
  - Пишет сообщения в основной топик.
  - Делает несколько попыток записи с задержкой между ними.
  - При окончательном фейле отправляет сообщение в DLQ-топик.
  - Генерирует idempotency key на основе имени и содержимого файла.

- **File processor**  
  - Сканирует NFS директорию.
  - Фильтрует файлы по расширению `.xml`.
  - Читает файл и отправляет контент через producer.
  - При успехе переносит файл в backup директорию.
  - Периодически чистит старые файлы из backup по retention-политике.

## Конфигурация

Конфигурация задаётся через файл `config.toml` и может быть переопределена переменными окружения.

### Пример `config.yaml`

```yaml
kafka:
  brokers:
    - "localhost:9092"
    - "localhost:9093"
  topic: "xml-files"
  dlq_topic: "xml-files-dlq"
  max_retries: 3
  retry_backoff_ms: 1000
  batch_timeout_ms: 100
  compression: "gzip"

storage:
  nfs_path: "/mnt/nfs/xml_files"
  backup_path: "/mnt/nfs/backup"
  backup_retention_days: 30

app:
  poll_interval_sec: 10
  log_level: "info"
```

### Переменные окружения (опционально)

Каждому полю соответствуют переменные окружения (если хочешь их использовать вместо/поверх YAML):

- `KAFKA_BROKERS` — список брокеров, через запятую.
- `KAFKA_TOPIC`
- `KAFKA_DLQ_TOPIC`
- `KAFKA_MAX_RETRIES`
- `KAFKA_RETRY_BACKOFF_MS`
- `KAFKA_BATCH_TIMEOUT_MS`
- `KAFKA_COMPRESSION`
- `NFS_PATH`
- `BACKUP_PATH`
- `BACKUP_RETENTION_DAYS`
- `APP_POLL_INTERVAL_SEC`
- `APP_LOG_LEVEL`

Если переменная не задана, используются значения из `config.yaml` или дефолты, прописанные в структурах конфигурации.

## Запуск

### Требования

- Go 1.25+
- Доступный кластер Kafka.
- Смонтированное NFS хранилище с XML файлами (или любая директория, к которой есть доступ).

### Установка зависимостей

В корне проекта:

```bash
go mod tidy
```

### Локальный запуск

```bash
go run ./cmd/main.go
```

При старте сервис:
- загружает конфигурацию;
- создаёт (если нужно) директорию backup;
- один раз очищает старые файлы в backup;
- запускает периодический цикл:
  - чтение XML файлов из NFS директории;
  - отправка в Kafka;
  - перенос в backup;
  - очистка устаревших файлов из backup.

Остановка по `Ctrl+C` или сигналу `SIGTERM` происходит аккуратно (graceful shutdown).

## Как работает idempotency

Для каждого файла считается хэш (например, MD5) от имени файла и его содержимого.  
Этот хэш используется в качестве `Key` сообщения в Kafka и также записывается в заголовки как `idempotency-key`.

Это позволяет:
- привязать повторную отправку к тому же ключу;
- минимизировать риск дублирующих записей на уровне потребителя, если он умеет обрабатывать ключи/idempotency.

Важно: гарантии «exactly-once» зависят от настроек Kafka и логики потребителя. Producer в этом проекте лишь создаёт стабильный idempotency key.

## Retry и DLQ

- Producer делает несколько попыток отправки сообщения в основной топик.
- Между попытками используется backoff, зависящий от номера попытки.
- Если после всех попыток отправка не удалась:
  - создаётся сообщение для DLQ-топика;
  - в заголовках указываются:
    - оригинальные заголовки;
    - причина отказа (`dlq-reason`);
    - время помещения в DLQ (`dlq-timestamp`).

Это позволяет отдельно обрабатывать плохие сообщения/файлы downstream-сервисами.

## Логика работы с файлами

Основной цикл:

1. Прочитать список файлов в `nfs_path`.
2. Отфильтровать директории и не-XML файлы.
3. Для каждого XML:
   - прочитать содержимое файла;
   - отправить в Kafka через producer;
   - при успехе переместить файл в `backup_path`.
4. После обработки файлов — пройтись по `backup_path` и удалить файлы, у которых возраст превышает `backup_retention_days`.

Файлы удаляются по `mtime` (времени последней модификации).  

## Структура проекта

```text
kafka-xml-producer/
├── cmd/
│   └── main.go             # Точка входа
├── internal/
│   ├── config/
│   │   └── config.go       # Загрузка и хранение конфигурации
│   ├── producer/
│   │   └── kafka_producer.go # Kafka producer, retry, DLQ, idempotency
│   └── processor/
│       └── file_processor.go # Работа с NFS файлами и backup
├── config.yaml            # Конфиг (пример/дефолт)
└── go.mod
```

## Как адаптировать под свой кейс

- Измени `kafka.topic` и `kafka.dlq_topic` под свою схему топиков.
- Настрой `storage.nfs_path` и `storage.backup_path` под свою файловую структуру.
- При необходимости:
  - добавь в заголовки сообщения дополнительные поля (идентификаторы, типы сообщений и т.п.);
  - измени стратегию idempotency (например, хэш только содержимого или добавление бизнес-ключа);
  - подключи метрики/обёртку для логирования (logrus, zap и т.д.).

Если нужно, можно отдельно дописать пример docker-compose для локального поднятия Kafka и NFS-like директории.
